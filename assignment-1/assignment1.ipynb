{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the random Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1  1  1  1  1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1  1 -1 -1 -1  1 -1\n",
      "  1 -1  1  1 -1 -1  1  1  1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1  1 -1\n",
      "  1 -1  1  1  1 -1  1  1 -1  1  1  1 -1  1  1 -1  1 -1 -1  1 -1 -1  1 -1\n",
      " -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1  1  1  1  1 -1  1 -1 -1 -1\n",
      " -1  1 -1  1]\n",
      "[[1.95308134e-01 7.98993353e-01 4.75689550e-01 8.95398497e-01\n",
      "  1.07940165e-01 9.03779672e-01 5.72325321e-01 5.75167111e-01\n",
      "  5.77609176e-01 2.59268131e-02]\n",
      " [4.01920901e-01 7.17031473e-01 8.22095305e-01 4.98535230e-01\n",
      "  6.84010833e-01 8.99425187e-01 2.37969460e-01 4.38075804e-01\n",
      "  9.09224164e-01 3.29484319e-01]\n",
      " [9.30846308e-01 1.90408500e-01 6.16041421e-01 9.00011847e-01\n",
      "  6.13387883e-01 7.15934359e-01 1.30317855e-01 7.50406615e-02\n",
      "  3.45122745e-01 9.17114738e-01]\n",
      " [8.76874822e-01 2.37296844e-01 6.79455538e-01 8.88564704e-01\n",
      "  2.01282615e-02 5.93740516e-01 6.11518228e-01 5.68840805e-01\n",
      "  9.27045654e-01 8.45448183e-01]\n",
      " [5.02701746e-01 2.72156381e-01 7.59799136e-01 3.25204401e-01\n",
      "  1.58050395e-01 8.65116786e-01 6.14559066e-01 4.42450112e-01\n",
      "  4.27991367e-01 4.73289940e-01]\n",
      " [2.65651086e-01 8.61497279e-01 9.99996180e-01 1.74601628e-01\n",
      "  2.97323249e-01 1.28121956e-01 2.15808858e-01 7.74154445e-01\n",
      "  8.90782985e-01 3.96141132e-01]\n",
      " [3.77335738e-01 9.11334535e-01 7.05092511e-01 9.47689305e-01\n",
      "  2.56747009e-01 4.20487099e-01 1.13904944e-01 4.54427106e-01\n",
      "  2.31398351e-01 9.55658667e-01]\n",
      " [2.31363814e-01 4.92057053e-01 7.52393957e-01 4.68057806e-01\n",
      "  4.53051943e-01 8.78912361e-01 4.85836407e-01 2.87834207e-01\n",
      "  1.86184416e-01 3.08120806e-01]\n",
      " [4.75117284e-01 4.70418222e-01 7.61470060e-02 6.64392029e-01\n",
      "  1.84436207e-01 2.86973207e-01 7.38263362e-01 9.11850841e-01\n",
      "  1.85834248e-04 2.00864151e-01]\n",
      " [2.28215872e-01 2.24942232e-01 4.55109315e-01 6.96906943e-01\n",
      "  3.02280571e-01 7.65990242e-01 2.89347620e-01 7.42242253e-01\n",
      "  4.74424553e-01 7.46667132e-01]\n",
      " [7.54717732e-01 4.47555308e-03 4.74871054e-01 2.16691939e-01\n",
      "  6.57365351e-01 4.45000141e-01 3.52807521e-01 8.04482720e-01\n",
      "  4.98976504e-01 2.50129811e-01]\n",
      " [3.34050345e-03 4.83632385e-01 3.95542957e-01 7.59809366e-01\n",
      "  5.09019739e-01 5.29255329e-01 8.09164676e-01 1.41776004e-01\n",
      "  2.39136842e-01 7.68161443e-02]\n",
      " [7.77598640e-01 1.44388888e-01 1.36157866e-01 1.56335258e-01\n",
      "  1.79794254e-01 9.16615293e-01 9.92050777e-01 4.52106721e-01\n",
      "  6.50908095e-02 5.49227276e-01]\n",
      " [9.55620184e-01 1.41139950e-01 3.87032966e-01 2.10801534e-01\n",
      "  9.93681929e-01 8.87971059e-01 3.15780618e-01 5.37958223e-01\n",
      "  9.71689838e-01 3.50365793e-03]\n",
      " [4.72903332e-01 7.26130755e-01 2.76628218e-01 2.87129980e-01\n",
      "  8.23033642e-02 7.02685018e-01 1.32453925e-02 2.86660126e-01\n",
      "  2.73592576e-01 8.88240493e-01]\n",
      " [4.81346875e-01 4.29703540e-01 2.44959048e-01 9.72803133e-01\n",
      "  3.08408346e-01 5.83223985e-01 8.27246063e-01 9.62766362e-01\n",
      "  4.86817063e-01 8.82943178e-01]\n",
      " [3.08969596e-01 2.12349338e-01 4.22193560e-02 3.64659672e-01\n",
      "  8.24586837e-01 7.56261425e-01 1.12240027e-01 5.45269396e-01\n",
      "  2.70823040e-01 6.82307522e-01]\n",
      " [1.70453622e-01 8.55855072e-01 1.41342589e-01 3.51449116e-01\n",
      "  7.97244986e-01 6.17874637e-01 9.17021591e-01 3.10329761e-01\n",
      "  7.63902995e-01 7.92075348e-02]\n",
      " [1.18719401e-01 4.43247364e-01 2.70971541e-01 6.02337691e-01\n",
      "  3.55570421e-01 4.69408052e-02 3.97447402e-01 7.07468100e-01\n",
      "  4.66444658e-01 9.31649175e-01]\n",
      " [3.63382728e-01 7.66646132e-01 5.81581421e-02 6.86062678e-01\n",
      "  7.40119857e-01 3.69145622e-01 8.12647513e-01 3.82577652e-01\n",
      "  4.21069705e-01 9.31856318e-01]\n",
      " [7.57732493e-01 6.42939067e-01 4.49781005e-01 6.23895037e-01\n",
      "  9.32207592e-01 4.49114934e-01 3.88042093e-01 3.74715875e-01\n",
      "  7.13639427e-01 4.18262249e-01]\n",
      " [3.24910308e-01 9.99225839e-01 5.90684836e-01 8.20822695e-01\n",
      "  2.28468394e-01 3.35069996e-01 9.69688211e-01 9.02558476e-01\n",
      "  6.15601163e-01 7.48256657e-01]\n",
      " [4.77365992e-01 4.72350030e-01 9.39910457e-01 9.28230436e-01\n",
      "  1.85580748e-01 4.86021036e-01 2.31185051e-01 7.09791446e-01\n",
      "  4.97809992e-01 8.59379018e-01]\n",
      " [9.07234717e-01 1.69369659e-01 7.32787310e-01 4.75073996e-01\n",
      "  4.06509142e-01 2.88397565e-01 2.74397698e-01 6.30217568e-01\n",
      "  3.89487238e-01 2.34412538e-01]\n",
      " [2.51226992e-01 1.78909639e-01 6.05401926e-01 4.50379628e-01\n",
      "  6.79014191e-01 2.85182266e-01 3.39193937e-03 5.64793322e-01\n",
      "  9.18265480e-01 7.25910853e-01]\n",
      " [6.70722110e-01 8.62784736e-01 2.47819329e-01 6.18664270e-01\n",
      "  3.34347051e-01 1.37262351e-01 1.50124519e-01 2.21127446e-01\n",
      "  3.64872276e-01 3.38238379e-01]\n",
      " [6.72968750e-01 9.03362810e-01 5.95705532e-01 7.74956138e-01\n",
      "  8.40974075e-01 2.43251303e-01 4.91998877e-01 3.44525494e-01\n",
      "  4.54007957e-01 9.17724800e-01]\n",
      " [5.40832157e-01 5.87860259e-01 8.54941151e-01 6.20123687e-01\n",
      "  6.29302284e-01 6.73215198e-01 5.83076715e-01 2.96526097e-01\n",
      "  3.01351513e-01 9.08914971e-01]\n",
      " [2.65336976e-01 4.96538247e-01 8.97677938e-01 8.41135973e-01\n",
      "  4.63537406e-02 5.17164986e-01 9.23003023e-01 4.39699579e-02\n",
      "  2.17898248e-01 8.37840583e-01]\n",
      " [9.02651152e-01 7.58766984e-01 2.46936285e-01 6.36190611e-01\n",
      "  3.97311942e-01 8.97472877e-01 2.99012363e-02 5.98854771e-01\n",
      "  3.74371337e-01 7.58705869e-01]\n",
      " [8.13461140e-01 1.16179575e-01 7.68894905e-01 5.80538732e-01\n",
      "  7.38303318e-01 3.06111922e-01 4.48083191e-01 9.75026169e-01\n",
      "  3.72481610e-01 8.22958163e-02]\n",
      " [5.74173252e-01 5.86521227e-01 4.29484125e-01 5.61932387e-01\n",
      "  5.11763868e-01 2.39320144e-01 8.18396627e-02 2.46337646e-02\n",
      "  3.55161365e-01 2.89816611e-01]\n",
      " [1.64300877e-01 8.20738824e-01 2.16750768e-01 6.70499399e-01\n",
      "  8.25031203e-02 7.65015653e-01 9.99067026e-01 6.96840280e-01\n",
      "  7.94136995e-01 8.98806032e-01]\n",
      " [7.64638942e-01 7.97903147e-01 4.73614486e-01 4.86533357e-01\n",
      "  7.00303456e-01 2.40939557e-01 2.47503015e-01 8.50277174e-01\n",
      "  8.39368871e-01 1.09479424e-01]\n",
      " [1.15120296e-01 4.24644140e-01 3.53582186e-01 2.61926147e-01\n",
      "  4.57406649e-01 2.21269616e-01 2.52920662e-01 8.73705918e-01\n",
      "  3.89740531e-01 2.70392591e-01]\n",
      " [9.20832965e-01 7.93602639e-01 7.04284837e-01 1.76751755e-01\n",
      "  8.51268005e-01 8.25500414e-01 7.19290388e-01 4.63054097e-01\n",
      "  7.16554727e-01 2.65722763e-01]\n",
      " [9.49087723e-01 9.03790324e-01 1.99858380e-01 9.70787169e-01\n",
      "  1.88604243e-01 1.82158162e-01 5.20101114e-01 3.22820391e-01\n",
      "  3.09659039e-01 9.10164125e-01]\n",
      " [9.53905786e-01 5.49349521e-02 8.53863357e-01 6.28682260e-01\n",
      "  5.98325382e-01 9.81032681e-01 2.28786703e-01 2.73398529e-01\n",
      "  5.69854220e-01 5.40872659e-01]\n",
      " [5.42003829e-01 4.10320899e-01 6.62005524e-01 1.43820157e-01\n",
      "  4.59311978e-01 3.08782882e-02 7.91153393e-01 5.19440951e-01\n",
      "  2.43097550e-01 9.53248011e-01]\n",
      " [7.17387800e-01 9.40894438e-01 8.56625136e-01 2.25086401e-01\n",
      "  7.31064002e-01 6.90952801e-02 8.17703027e-01 9.76839136e-01\n",
      "  6.71883865e-01 8.20589603e-01]\n",
      " [7.94501930e-01 5.91193070e-01 7.90269028e-01 8.19121998e-01\n",
      "  4.31081952e-02 8.23043959e-02 8.39054706e-01 8.00258168e-01\n",
      "  6.74997927e-01 3.26730923e-01]\n",
      " [5.65809045e-01 9.90353243e-01 8.39097087e-02 1.55149576e-01\n",
      "  9.70587930e-01 5.73489467e-01 5.10471630e-01 7.38855651e-01\n",
      "  6.06917272e-01 7.88840186e-01]\n",
      " [1.06409035e-01 1.03926103e-01 6.32595858e-01 6.59934437e-01\n",
      "  5.53762244e-01 8.33388030e-01 6.84362232e-01 9.97571527e-01\n",
      "  2.09270163e-01 4.61649323e-02]\n",
      " [8.28453420e-01 6.17543563e-01 5.27628624e-01 4.14894279e-01\n",
      "  7.47842264e-01 1.45276311e-01 3.24936871e-01 3.83768052e-02\n",
      "  6.50184605e-01 7.81548928e-01]\n",
      " [9.26807869e-01 8.89825971e-01 6.78610372e-01 1.42299021e-02\n",
      "  4.49637063e-01 7.56506623e-02 1.22490766e-01 4.29204007e-01\n",
      "  5.85502544e-01 1.91850967e-01]\n",
      " [1.41163044e-01 1.88379552e-01 5.54599978e-01 6.45220656e-01\n",
      "  3.34529222e-01 8.62433195e-01 8.11179706e-01 4.04698658e-01\n",
      "  1.89488371e-01 8.39135834e-01]\n",
      " [4.35228436e-01 3.26005421e-02 5.76516398e-01 8.78816367e-01\n",
      "  1.46989787e-01 3.49490502e-01 4.77161653e-01 8.68487735e-01\n",
      "  2.59693531e-01 9.82399781e-01]\n",
      " [3.45537403e-01 6.92400766e-01 1.19105484e-01 3.18348797e-01\n",
      "  7.89922695e-01 2.46745755e-01 2.48174091e-01 3.12755281e-01\n",
      "  3.46810811e-01 8.18300867e-01]\n",
      " [7.52899623e-01 4.94041420e-01 2.81364334e-01 3.61096910e-01\n",
      "  5.79508156e-02 2.73550583e-01 2.10524412e-01 8.82889530e-02\n",
      "  5.91819443e-01 3.05455377e-01]\n",
      " [7.84227097e-01 2.78727811e-01 6.07613103e-01 5.62432043e-01\n",
      "  8.01792239e-01 3.48925457e-01 2.06920496e-01 1.06178320e-01\n",
      "  3.84091984e-01 2.00693260e-01]\n",
      " [6.06520427e-01 1.22113842e-01 2.53523292e-01 7.41368592e-01\n",
      "  1.33357679e-02 9.37245097e-01 3.90402403e-01 2.60842309e-02\n",
      "  4.58338111e-02 1.17263042e-01]\n",
      " [6.25075867e-01 2.50082029e-01 4.70420332e-02 1.41336563e-01\n",
      "  8.12699107e-01 8.67733309e-01 1.77655998e-01 2.73436046e-02\n",
      "  7.20018142e-01 7.82642343e-01]\n",
      " [6.80188580e-02 9.37202424e-01 8.36137694e-01 9.16732683e-01\n",
      "  6.87838449e-01 9.38673341e-01 9.17635402e-01 3.23265513e-01\n",
      "  6.47469949e-01 5.13187588e-01]\n",
      " [2.31736908e-01 8.06979318e-01 7.38262426e-01 6.88623943e-03\n",
      "  5.87212576e-01 6.52477479e-01 8.97291573e-01 1.16488188e-01\n",
      "  6.72300920e-01 3.17975166e-01]\n",
      " [5.04955292e-01 4.92017250e-01 7.01319414e-01 9.16968730e-01\n",
      "  3.98582672e-02 9.61650851e-01 2.19929853e-01 3.18247019e-01\n",
      "  1.50397313e-01 8.68968773e-01]\n",
      " [4.99138341e-01 1.77581409e-01 4.94593605e-01 1.84146004e-01\n",
      "  3.10273170e-01 7.55641822e-01 2.98977178e-01 6.43755561e-02\n",
      "  1.62121307e-01 6.84928517e-01]\n",
      " [7.70753813e-01 1.99885925e-01 9.71290287e-01 6.05361848e-01\n",
      "  6.13937339e-01 7.35957129e-01 9.63276968e-02 1.04277629e-01\n",
      "  2.72170836e-01 6.19628994e-01]\n",
      " [6.50621328e-01 6.52753455e-02 6.09868903e-01 1.48407244e-01\n",
      "  2.55854479e-01 4.93833691e-01 4.61757434e-02 5.26138710e-01\n",
      "  8.74260791e-02 7.75918301e-01]\n",
      " [7.33562403e-01 2.15925234e-02 4.39171360e-02 1.17890944e-01\n",
      "  1.11232222e-01 8.34905201e-01 7.73678137e-03 7.08291160e-01\n",
      "  8.18925365e-01 1.00190342e-01]\n",
      " [6.20209726e-01 3.62160730e-02 1.67225449e-01 7.05365010e-01\n",
      "  9.43998544e-01 2.00310456e-01 3.63185771e-01 8.26384438e-01\n",
      "  4.92485606e-01 2.88051334e-01]\n",
      " [1.99453137e-01 3.43252855e-01 4.13973219e-02 4.74791989e-01\n",
      "  1.14608088e-01 4.55601889e-01 8.91545524e-01 5.40984994e-01\n",
      "  7.52319418e-01 8.58371479e-01]\n",
      " [1.80573126e-01 2.57652228e-01 5.51769810e-01 2.77866456e-01\n",
      "  3.93558618e-01 6.41872999e-01 3.25361397e-01 8.82578261e-02\n",
      "  3.61761522e-01 3.60587312e-01]\n",
      " [1.92232883e-01 1.82121810e-01 7.25223771e-01 3.53907778e-01\n",
      "  4.88559319e-01 8.97529446e-01 5.50415166e-02 5.78938195e-01\n",
      "  5.60523295e-01 7.31558313e-01]\n",
      " [7.15791918e-01 7.57085103e-01 8.58914499e-01 3.39144049e-01\n",
      "  6.91665403e-01 7.37457506e-01 5.84351920e-01 9.42010600e-01\n",
      "  9.61662055e-01 4.49808553e-01]\n",
      " [4.39640664e-01 1.84573217e-01 1.42354618e-01 6.46265415e-01\n",
      "  2.53050386e-01 4.08514934e-01 3.07358164e-01 7.15927929e-01\n",
      "  7.49999238e-02 2.43531403e-01]\n",
      " [8.50476026e-01 4.09412769e-01 1.04436378e-01 7.98937289e-01\n",
      "  9.27083429e-01 7.32260608e-01 2.59540759e-01 9.94808764e-01\n",
      "  2.95751929e-01 6.91675764e-01]\n",
      " [4.00478301e-01 7.51932446e-01 4.51988604e-01 3.05039642e-02\n",
      "  3.51037926e-01 1.80715323e-01 6.72201879e-01 4.80252344e-01\n",
      "  6.19516540e-01 8.72948017e-01]\n",
      " [3.50308673e-01 3.60264214e-01 6.46570043e-01 9.47938768e-01\n",
      "  8.64436770e-01 3.90933705e-01 2.75655780e-02 8.78443487e-01\n",
      "  5.36112567e-01 9.04137521e-01]\n",
      " [7.24069192e-01 9.18579876e-01 5.12310942e-01 8.05541344e-01\n",
      "  7.07168108e-01 9.01779317e-01 3.94131741e-01 1.74064496e-01\n",
      "  2.41752900e-01 8.36685180e-01]\n",
      " [1.47006206e-01 6.90269572e-01 4.90370874e-01 9.84741241e-01\n",
      "  4.98662824e-01 4.53001591e-01 3.60352729e-01 1.59765325e-01\n",
      "  7.57196882e-01 5.84456106e-01]\n",
      " [6.84235907e-01 1.11038218e-01 5.30186064e-01 1.31837711e-01\n",
      "  4.87113358e-01 4.52564759e-01 9.47986699e-01 8.31650674e-01\n",
      "  2.97800492e-01 1.45066880e-01]\n",
      " [1.40599297e-01 8.02523706e-01 2.04583563e-01 6.78356880e-01\n",
      "  7.33418054e-03 1.48273823e-01 2.36950789e-01 6.09601302e-01\n",
      "  7.60803383e-02 7.91025739e-01]\n",
      " [2.49039122e-01 3.47484671e-01 2.62669052e-01 7.80613222e-01\n",
      "  4.37249139e-01 7.95744219e-01 9.68865712e-01 1.33405241e-01\n",
      "  6.44264527e-01 8.48117517e-01]\n",
      " [6.86530004e-01 4.43352585e-01 3.02258199e-01 8.20635399e-01\n",
      "  1.30271226e-01 8.86431841e-02 5.18886262e-01 2.33655819e-01\n",
      "  6.26675566e-01 9.55513737e-01]\n",
      " [6.33576163e-01 4.51498950e-01 5.46933313e-01 8.39513508e-01\n",
      "  5.73427580e-01 4.67202084e-03 1.60697376e-01 7.37856695e-01\n",
      "  6.20863552e-01 9.91356578e-02]\n",
      " [8.37622846e-01 1.54585793e-01 9.85130268e-01 1.37281599e-01\n",
      "  3.29347968e-01 1.32165507e-01 5.32724313e-01 3.57112491e-01\n",
      "  6.91740344e-01 2.57539265e-01]\n",
      " [6.85495720e-02 1.32394545e-01 3.39437228e-01 7.16975076e-01\n",
      "  8.26094064e-01 5.57597647e-01 5.57505479e-01 2.02285910e-01\n",
      "  7.50865665e-01 2.66620870e-01]\n",
      " [7.12506480e-01 5.01007376e-01 5.92592421e-01 2.38528112e-01\n",
      "  9.73989137e-01 5.05739627e-01 1.81677940e-01 5.68271723e-01\n",
      "  4.04821771e-01 4.84755470e-01]\n",
      " [2.50096450e-01 6.01931329e-01 5.17671503e-01 3.18776838e-02\n",
      "  9.26111362e-01 5.20432884e-01 8.83814052e-01 5.68722575e-01\n",
      "  3.57363551e-01 7.61601642e-01]\n",
      " [5.49169046e-01 3.19147869e-01 2.79944385e-01 3.12405378e-01\n",
      "  6.60065670e-01 1.75296591e-01 1.28732405e-01 7.18332715e-02\n",
      "  9.21571178e-01 2.82040726e-01]\n",
      " [5.01447244e-01 4.36686960e-01 7.05442637e-01 7.87544683e-01\n",
      "  2.12445410e-01 2.59407625e-01 6.36805860e-01 2.14324760e-01\n",
      "  9.63880999e-01 2.81017045e-01]\n",
      " [5.19539232e-01 8.04220632e-01 2.93771303e-02 1.25300930e-01\n",
      "  4.54830190e-02 6.68232858e-01 4.24638901e-01 6.55773801e-01\n",
      "  6.64772758e-01 3.07043961e-02]\n",
      " [1.02403560e-01 4.58333906e-01 5.47029699e-01 8.79034265e-01\n",
      "  4.56350582e-01 5.41660612e-01 5.76380728e-01 2.72110030e-03\n",
      "  3.86787038e-01 9.92279176e-01]\n",
      " [1.42340691e-01 8.02848873e-01 2.47597196e-01 7.36023702e-01\n",
      "  7.88225663e-01 1.91776163e-01 3.82325562e-01 8.06237270e-01\n",
      "  6.09044311e-01 3.62559760e-01]\n",
      " [7.98923478e-02 3.61654258e-01 5.43762145e-01 2.84805686e-01\n",
      "  2.72506381e-01 9.60405956e-01 8.95513974e-01 7.99683295e-01\n",
      "  4.78252094e-01 3.37070809e-01]\n",
      " [5.16451611e-01 7.13199983e-01 4.25210386e-01 9.92735760e-01\n",
      "  3.50968538e-01 4.88463599e-01 2.73635981e-01 8.86407164e-01\n",
      "  6.78749626e-01 4.31233648e-01]\n",
      " [8.80550150e-01 4.40572379e-01 4.81692179e-01 5.87166910e-01\n",
      "  4.29827144e-01 3.67479374e-01 4.39711227e-01 2.64590622e-01\n",
      "  2.01623116e-01 4.59412697e-01]\n",
      " [6.64756557e-01 4.58865508e-01 7.18595010e-01 1.13663426e-01\n",
      "  3.20383342e-01 1.81571599e-01 7.25003303e-01 3.90513022e-02\n",
      "  2.62789318e-01 1.20416730e-02]\n",
      " [3.43345532e-01 5.74071407e-02 7.10500248e-01 3.53404189e-01\n",
      "  1.91491268e-01 7.39606555e-01 9.28910344e-01 3.81393078e-01\n",
      "  4.11887037e-01 2.21507069e-01]\n",
      " [3.06068179e-01 1.23554024e-01 6.63401003e-01 4.93518542e-01\n",
      "  6.29554246e-01 8.67532995e-01 4.07714555e-01 8.99033924e-01\n",
      "  4.33305900e-01 4.41140680e-01]\n",
      " [3.29688603e-01 1.85166821e-01 7.14049363e-01 1.18981312e-01\n",
      "  1.84099072e-01 4.42368515e-01 2.85686516e-01 9.53231594e-01\n",
      "  1.69442439e-01 8.73096140e-01]\n",
      " [2.98705307e-01 3.76275879e-01 3.07161115e-01 7.16117576e-01\n",
      "  8.94892642e-01 7.59893421e-01 5.24657036e-01 7.33627783e-01\n",
      "  4.41155419e-01 1.52779835e-01]\n",
      " [6.26596965e-01 2.86692665e-01 7.38898583e-01 6.66681133e-01\n",
      "  2.43348598e-01 2.60701771e-01 5.80016957e-01 8.31579032e-01\n",
      "  2.47628624e-01 4.38968718e-02]\n",
      " [3.76290623e-01 7.00281697e-01 9.49175935e-01 9.23752623e-02\n",
      "  5.23961372e-01 3.17730686e-01 7.44385916e-01 4.26466118e-01\n",
      "  5.27713672e-01 1.50204946e-01]\n",
      " [2.53298840e-01 6.25182382e-01 1.43868596e-03 1.32028705e-01\n",
      "  8.94980751e-01 7.38247847e-01 6.48464433e-01 8.29359022e-01\n",
      "  8.03119383e-01 9.89128772e-01]\n",
      " [4.27088704e-01 9.56880336e-01 5.16032264e-01 1.31204692e-01\n",
      "  7.62887970e-01 5.17061312e-01 2.98492977e-01 5.23505275e-01\n",
      "  2.15481996e-01 8.20472090e-01]\n",
      " [6.55739304e-01 5.54309007e-01 1.78904702e-01 5.33413068e-01\n",
      "  8.87983953e-01 9.02562090e-01 3.27405866e-03 8.85859165e-01\n",
      "  8.43007655e-01 3.65359263e-01]\n",
      " [9.76940621e-01 6.32905458e-02 6.53266703e-02 9.81283990e-01\n",
      "  2.26797265e-01 6.49744931e-01 5.61961842e-01 3.62745788e-01\n",
      "  5.49506455e-01 4.45790158e-01]\n",
      " [6.29621584e-02 3.97663044e-01 5.16917618e-01 1.23000422e-01\n",
      "  5.81183338e-01 3.06094435e-01 6.27782271e-01 1.82138565e-01\n",
      "  1.46338291e-01 8.33227737e-01]\n",
      " [5.69038115e-01 9.48013919e-01 7.72790825e-01 6.47400489e-02\n",
      "  7.18390745e-01 8.93891596e-01 8.02877920e-01 2.50088794e-01\n",
      "  9.03173117e-02 3.30580606e-01]]\n"
     ]
    }
   ],
   "source": [
    "# We first generate a random dataset with number of features (m = 10) and number of instances (n = 100)\n",
    "# We also generate a random label vector y \\in {-1,1}\n",
    "\n",
    "n = 100 # Number of instances\n",
    "m = 10  # Number of Features\n",
    "\n",
    "X = np.random.rand(n,m)\n",
    "y = np.random.rand(n) # n-dimensional vector\n",
    "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
    "y = np.array(ybin)\n",
    "w = np.random.rand(m) # m-dimensional vector\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Implementation of the Logistic Loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticLossNaive(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    Z = 1e3 # To prevent overflow in exp\n",
    "    eps = 1e-12 # For numerical stability in log computation\n",
    "    \n",
    "    f = 0.0\n",
    "    (n, m) = X.shape\n",
    "    y_pred = np.zeros(n)\n",
    "    # Cost function\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            y_pred[i] += w[j] * X[i][j] \n",
    "            \n",
    "        f += np.log(1 + np.exp(-y[i] * y_pred[i] / Z) + eps)\n",
    "        \n",
    "    for j in range(m):\n",
    "        f += (lam * w[j] * w[j]) / 2\n",
    "    \n",
    "    # Gradient\n",
    "    g = np.zeros(m)\n",
    "    for k in range(m):\n",
    "        for i in range(n):\n",
    "            g[k] += -1 / Z * y[i] * X[i][k] / (1 + np.exp(y_pred[i] * y[i] / Z))\n",
    "            \n",
    "        g[k] += lam * w[k]\n",
    "    \n",
    "    return [f, g]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken = 0.00404810905456543\n",
      "Function value = 70.7717943578683\n",
      "Printing Gradient:\n",
      "[0.44762367 0.08973384 0.31585168 0.40553753 0.86898475 0.95854302\n",
      " 0.04003747 0.09037728 0.82529141 0.27722872]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "[f,g] = LogisticLossNaive(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Implementation of the Least Squares \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquaresNaive(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    f = 0.0\n",
    "    (n, m) = X.shape\n",
    "    y_pred = np.zeros(n)\n",
    "    # Cost function\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            y_pred[i] += w[j] * X[i][j] \n",
    "            \n",
    "        f += (y[i] - y_pred[i]) ** 2\n",
    "        \n",
    "    for j in range(m):\n",
    "        f += (lam * w[j] * w[j]) / 2\n",
    "    \n",
    "    # Gradient\n",
    "    g = np.zeros(m)\n",
    "    for k in range(m):\n",
    "        for i in range(n):\n",
    "            g[k] += 2 * (y_pred[i] - y[i]) * X[i][k]\n",
    "            \n",
    "        g[k] += lam * w[k]\n",
    "        \n",
    "    return [f, g]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken = 0.0013513565063476562\n",
      "Function value = 592.4418387511391\n",
      "Printing Gradient:\n",
      "[218.78777935 223.94225295 207.13676927 230.3816916  233.02343169\n",
      " 229.52959471 203.56834853 216.14121597 225.23050176 231.09580668]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "[f,g] = LeastSquaresNaive(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Implementation of the Hinge Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HingeLossNaive(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    f = 0.0\n",
    "    (n, m) = X.shape\n",
    "    y_pred = np.zeros(n)\n",
    "    # Cost function\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            y_pred[i] += w[j] * X[i][j] \n",
    "            \n",
    "        f += max(0, 1 - y[i] * y_pred[i])\n",
    "        \n",
    "    for j in range(m):\n",
    "        f += (lam * w[j] * w[j]) / 2\n",
    "    \n",
    "    # Gradient\n",
    "    g = np.zeros(m)\n",
    "    for k in range(m):\n",
    "        for i in range(n):\n",
    "            if y_pred[i]*y[i] <= 1:\n",
    "                g[k] += -1 * y[i] * X[i][k]\n",
    "            \n",
    "        g[k] += lam * w[k]\n",
    "    \n",
    "    return [f, g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken = 0.002384662628173828\n",
      "Function value = 162.0859208106271\n",
      "Printing Gradient:\n",
      "[25.18041011 28.14926623 23.18463409 27.56012733 27.42301974 24.89255245\n",
      " 24.98899065 25.32120959 26.64823403 27.18671608]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "[f,g] = HingeLossNaive(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Loss\n",
      "Time Taken = 3.898196220397949\n",
      "Function value = [1796.54727871]\n",
      "Printing Gradient:\n",
      "[0.8400511  0.18189239 0.80721711 ... 0.02633613 0.36537191 1.00021811]\n",
      "Least Square\n",
      "Time Taken = 2.2098374366760254\n",
      "Function value = [6.27662628e+08]\n",
      "Printing Gradient:\n",
      "[244757.08304822 254686.46205992 249341.92352536 ... 237448.77319858\n",
      " 245402.92231102 254711.99661506]\n",
      "Hinge Loss\n",
      "Time Taken = 2.2023420333862305\n",
      "Function value = [114355.70860497]\n",
      "Printing Gradient:\n",
      "[23.74126879 23.25239655 21.58371545 ... 18.64416456 23.35025911\n",
      " 23.26455111]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "m = 10000\n",
    "\n",
    "X = np.random.rand(n,m)\n",
    "y = np.random.rand(n)\n",
    "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
    "y = np.array(ybin)\n",
    "w = np.random.rand(m, 1)\n",
    "\n",
    "start = time.time()\n",
    "[f,g] = LogisticLossNaive(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Logistic Loss\")\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)\n",
    "\n",
    "start = time.time()\n",
    "[f,g] = LeastSquaresNaive(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Least Square\")\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)\n",
    "\n",
    "start = time.time()\n",
    "[f,g] = HingeLossNaive(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Hinge Loss\")\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a vectorized version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticLossVec(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    Z = 1e3 # To prevent overflow in exp\n",
    "    eps = 1e-12 # For numerical stability in log computation\n",
    "    \n",
    "    y_pred = X @ w\n",
    "    f = np.sum(np.log(1 + np.exp(-y_pred * y / Z) + eps)) + lam * np.linalg.norm(w) / 2\n",
    "    g = - X.T / Z @ (y / (1 + np.exp(y * y_pred / Z))) + lam * w\n",
    "    return [f, g]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquaresVec(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    y_pred = X @ w\n",
    "    f = np.sum((y_pred - y) ** 2) + lam * np.linalg.norm(w) / 2\n",
    "    g = 2 * X.T @ (y_pred - y) + lam * w\n",
    "    return [f, g]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HingeLossVec(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    y_pred = X @ w\n",
    "    f = np.sum((1 >= y_pred * y) * (1 - y_pred*y)) + lam * np.linalg.norm(w) / 2\n",
    "    g = - X.T @ ((1 >= y_pred * y) * y) + lam * w\n",
    "    return [f, g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Loss\n",
      "Time Taken = 0.01532602310180664\n",
      "Function value = 12526.878008560307\n",
      "Printing Gradient:\n",
      "[[0.68991544 0.73797091 0.73797091 ... 0.68991544 0.68991544 0.73797091]\n",
      " [0.49476298 0.54481732 0.54481732 ... 0.49476298 0.49476298 0.54481732]\n",
      " [0.99288557 1.04056825 1.04056825 ... 0.99288557 0.99288557 1.04056825]\n",
      " ...\n",
      " [0.38752089 0.43914399 0.43914399 ... 0.38752089 0.38752089 0.43914399]\n",
      " [0.43486326 0.48552706 0.48552706 ... 0.43486326 0.43486326 0.48552706]\n",
      " [0.47084739 0.51805012 0.51805012 ... 0.47084739 0.47084739 0.51805012]]\n",
      "Least Square\n",
      "Time Taken = 0.011134862899780273\n",
      "Function value = 61982037399.058685\n",
      "Printing Gradient:\n",
      "[[239246.47191507 239438.69375845 239438.69375845 ... 239246.47191507\n",
      "  239246.47191507 239438.69375845]\n",
      " [249244.78500667 249445.00236645 249445.00236645 ... 249244.78500667\n",
      "  249244.78500667 249445.00236645]\n",
      " [237091.93462334 237282.66532823 237282.66532823 ... 237091.93462334\n",
      "  237091.93462334 237282.66532823]\n",
      " ...\n",
      " [257111.25747339 257317.74988671 257317.74988671 ... 257111.25747339\n",
      "  257111.25747339 257317.74988671]\n",
      " [252291.95749785 252494.61267781 252494.61267781 ... 252291.95749785\n",
      "  252291.95749785 252494.61267781]\n",
      " [234864.60113777 235053.41204521 235053.41204521 ... 234864.60113777\n",
      "  234864.60113777 235053.41204521]]\n",
      "Hinge Loss\n",
      "Time Taken = 0.0076906681060791016\n",
      "Function value = 11706000.869341876\n",
      "Printing Gradient:\n",
      "[[ 0.69359413 48.74905497 48.74905497 ...  0.69359413  0.69359413\n",
      "  48.74905497]\n",
      " [ 0.49859303 50.55293297 50.55293297 ...  0.49859303  0.49859303\n",
      "  50.55293297]\n",
      " [ 0.99654628 48.6792225  48.6792225  ...  0.99654628  0.99654628\n",
      "  48.6792225 ]\n",
      " ...\n",
      " [ 0.39146896 52.01457229 52.01457229 ...  0.39146896  0.39146896\n",
      "  52.01457229]\n",
      " [ 0.43873945 51.10253444 51.10253444 ...  0.43873945  0.43873945\n",
      "  51.10253444]\n",
      " [ 0.47446559 47.67719245 47.67719245 ...  0.47446559  0.47446559\n",
      "  47.67719245]]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "m = 10000\n",
    "\n",
    "X = np.random.rand(n,m)\n",
    "y = np.random.rand(n)\n",
    "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
    "y = np.array(ybin)\n",
    "w = np.random.rand(m, 1)\n",
    "\n",
    "start = time.time()\n",
    "[f,g] = LogisticLossVec(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Logistic Loss\")\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)\n",
    "\n",
    "start = time.time()\n",
    "[f,g] = LeastSquaresVec(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Least Square\")\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)\n",
    "\n",
    "start = time.time()\n",
    "[f,g] = HingeLossVec(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Hinge Loss\")\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value = \" + str(f))\n",
    "print(\"Printing Gradient:\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets us code the above Loss Fuctions in CVXPY!\n",
    "\n",
    "CVXPY is an open source Python-embedded modeling language for convex optimization problems. Link: https://www.cvxpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticLossCVXPY(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    Z = 1e3 # To prevent overflow in exp\n",
    "    eps = 1e-12 # For numerical stability in log computation\n",
    "    \n",
    "    expression = cp.sum(cp.log(1 + cp.exp(cp.multiply(-y, X @ w / Z)) + eps)) + lam * cp.norm(w, 2) / 2\n",
    "    Problem = cp.Problem(cp.Minimize(expression))\n",
    "    f = expression.value\n",
    "    g = - X.T / Z @ (y / (1 + np.exp(y * (X @ w) / Z))) + lam * w\n",
    "    \n",
    "    result = Problem.solve()\n",
    "    print(result)\n",
    "    return [f, g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquaresCVXPY(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    expression = cp.sum_squares((X @ w) - y) + lam * cp.norm(w, 2) / 2\n",
    "    Problem = cp.Problem(cp.Minimize(expression))\n",
    "    f = expression.value\n",
    "    g = 2 * X.T @ ((X @ w) - y) + lam * w\n",
    "    \n",
    "    result = Problem.solve()\n",
    "    print(result)\n",
    "    return [f, g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HingeLossCVXPY(w, X, y, lam):\n",
    "    # Computes the cost function for all the training samples\n",
    "    # where f is the function value and g is the gradient\n",
    "    expression = cp.sum(cp.pos(1 - cp.multiply(y, X @ w))) + lam * cp.norm(w, 2) / 2\n",
    "    Problem = cp.Problem(cp.Minimize(expression))\n",
    "    f = expression.value\n",
    "    g = - X.T @ ((1 >= (X @ w) * y) * y) + lam * w\n",
    "    \n",
    "    result = Problem.solve()\n",
    "    print(result)\n",
    "    return [f, g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.21460182595393\n",
      "Time Taken = 0.0022406578063964844\n",
      "Function value Naive = 70.21460182595393\n",
      "Printing Gradient Naive:\n",
      "[0.13117278 0.88521648 0.67992077 0.79986368 0.46976144 0.01714045\n",
      " 0.61592522 0.08380271 0.86977947 0.18002219]\n",
      "660.935095774148\n",
      "Time Taken = 0.0006556510925292969\n",
      "Function value For = 660.935095774148\n",
      "Printing Gradient For:\n",
      "[224.16526672 241.08679636 223.91489436 233.56189177 243.81953599\n",
      " 211.72779837 255.79942849 258.12841761 280.71813562 229.49904144]\n",
      "154.7038512226803\n",
      "Time Taken = 0.001323699951171875\n",
      "Function value For = 154.7038512226803\n",
      "Printing Gradient For:\n",
      "[22.1607932  22.33024964 22.11988189 20.93164732 22.54999438 21.7243705\n",
      " 25.34241544 26.53443661 27.98528822 22.71092706]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 100\n",
    "m = 10\n",
    "\n",
    "X = np.random.rand(n,m)\n",
    "y = np.random.rand(n)\n",
    "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
    "y = np.array(ybin)\n",
    "w = np.random.rand(m)\n",
    "\n",
    "start = time.time()\n",
    "[f1,g1] = LogisticLossCVXPY(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value Naive = \" + str(f1))\n",
    "print(\"Printing Gradient Naive:\")\n",
    "print(g1)\n",
    "\n",
    "start = time.time()\n",
    "[f2,g2] = LeastSquaresCVXPY(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value For = \" + str(f2))\n",
    "print(\"Printing Gradient For:\")\n",
    "print(g2)\n",
    "\n",
    "start = time.time()\n",
    "[f2,g2] = HingeLossCVXPY(w,X,y,1)\n",
    "end = time.time()\n",
    "print(\"Time Taken = \" + str(end - start))\n",
    "print(\"Function value For = \" + str(f2))\n",
    "print(\"Printing Gradient For:\")\n",
    "print(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the losses with Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticLossFun(w, X, y, lam):\n",
    "    return error_ll\n",
    "\n",
    "def LeastSquaresFun(w, X, y, lam):\n",
    "    return error_ls\n",
    "\n",
    "def HingeLossFun(w, X, y, lam):\n",
    "    return error_hl\n",
    "\n",
    "def plot_errors(error_ll, error_ls, error_hl, num):\n",
    "    plt.plot(num, error_ll, label=\"Logistic Loss\")\n",
    "    plt.plot(num, error_ls, label=\"Least Squares\")\n",
    "    plt.plot(num, error_hl, label=\"Hinge Loss\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "m = 10000\n",
    "\n",
    "X = np.random.rand(n,m)\n",
    "y = np.random.rand(n)\n",
    "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
    "y = np.array(ybin)\n",
    "w = np.random.rand(m, 1)\n",
    "\n",
    "error_ll = LogisticLossFun(w,X,y,1)\n",
    "error_ls = LeastSquaresFun(w,X,y,1)\n",
    "error_hl = HingeLossFun(w,X,y,1)\n",
    "plot_errors(error_ll, error_ls, error_hl, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
